# ì¼€ë¼ìŠ¤ ì½”ì–´ ì‹œì‘í•˜ê¸° (Getting started with Keras Core)
**ì €ì:** [fchollet](https://twitter.com/fchollet)<br>
**ì—­ì:** [ì¡°ìš©ì€](https://www.github.com/gdakate)<br>
**ìƒì„± ë‚ ì§œ:** 2023/07/10<br>
**ë§ˆì§€ë§‰ ìˆ˜ì •:** 2023/07/10<br>
**ë²ˆì—­ ì¼ì:** 2023/10/15<br>
**ì„¤ëª…:** ìƒˆë¡œìš´ ë©€í‹° ë°±ì—”ë“œ ì¼€ë¼ìŠ¤ì™€ì˜ ì²« ë§Œë‚¨.

#ì†Œê°œ (Introduction)
ì¼€ë¼ìŠ¤ ì½”ì–´ëŠ” TensorFlow, JAX, ê·¸ë¦¬ê³  PyTorchì™€ ìƒí˜¸êµí™˜í•  ìˆ˜ ìˆê²Œ ì‘ë™í•˜ëŠ” Keras APIì˜ ì™„ì „í•œ êµ¬í˜„ì…ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì€ ì—¬ëŸ¬ë¶„ì—ê²Œ ì¼€ë¼ìŠ¤ ì½”ì–´ì˜ ì£¼ìš” ì‘ì—… íë¦„ì„ ì•ˆë‚´í•  ê²ƒì…ë‹ˆë‹¤.

ë¨¼ì €, ì¼€ë¼ìŠ¤ ì½”ì–´ë¥¼ ì„¤ì¹˜í•´ë´…ì‹œë‹¤:


```python
!pip install -q keras-core
```

#ì„¤ì • (Setup)
ìš°ë¦¬ëŠ” ì—¬ê¸°ì—ì„œ JAX ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤ -- í•˜ì§€ë§Œ ì•„ë˜ì˜ ë¬¸ìì—´ì„ `"tensorflow"` ë˜ëŠ” `"torch"`ë¡œ ìˆ˜ì •í•˜ê³  "Restart runtime"ì„ ëˆ„ë¥´ë©´, ì „ì²´ ë…¸íŠ¸ë¶ì€ ë™ì¼í•˜ê²Œ ì‹¤í–‰ë  ê²ƒì…ë‹ˆë‹¤! ì´ ì „ì²´ ê°€ì´ë“œëŠ” ë°±ì—”ë“œì— êµ¬ì• ë°›ì§€ ì•ŠìŠµë‹ˆë‹¤.


```python
import numpy as np
import os

os.environ["KERAS_BACKEND"] = "jax"

# ë°±ì—”ë“œê°€ êµ¬ì„±ëœ í›„ì—ë§Œ keras_coreë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
# íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜¨ í›„ì—ëŠ” ë°±ì—”ë“œë¥¼ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

import keras_core as keras
```

#ì²« ë²ˆì§¸ ì˜ˆì œ: MNIST ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ (A first example: A MNIST convnet)
MLì˜ Hello Worldë¶€í„° ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤: ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ì„ í›ˆë ¨ì‹œì¼œ MNIST ìˆ«ìë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

ë‹¤ìŒì€ ë°ì´í„°ì…ë‹ˆë‹¤:


```python
# ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# ì´ë¯¸ì§€ë¥¼ [0, 1] ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤
x_train = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255
# ì´ë¯¸ì§€ê°€ (28, 28, 1)ì˜ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)
print(x_train.shape[0], "train samples")
print(x_test.shape[0], "test samples")
```

ë‹¤ìŒì€ ìš°ë¦¬ì˜ ëª¨ë¸ì…ë‹ˆë‹¤.

ì¼€ë¼ìŠ¤ê°€ ì œê³µí•˜ëŠ” ë‹¤ì–‘í•œ ëª¨ë¸ ë¹Œë“œ ì˜µì…˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- [The Sequential API](https://keras.io/keras_core/guides/sequential_model/) (ì•„ë˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•)
- [The Functional API](https://keras.io/keras_core/guides/functional_api/) (ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©)
- [Writing your own models yourself via subclassing](https://keras.io/keras_core/guides/making_new_layers_and_models_via_subclassing/) (ê³ ê¸‰ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ìœ„í•œ)


```python
# ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ë“¤
num_classes = 10
input_shape = (28, 28, 1)

model = keras.Sequential(
    [
        keras.layers.Input(shape=input_shape),
        keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        keras.layers.MaxPooling2D(pool_size=(2, 2)),
        keras.layers.Conv2D(128, kernel_size=(3, 3), activation="relu"),
        keras.layers.Conv2D(128, kernel_size=(3, 3), activation="relu"),
        keras.layers.GlobalAveragePooling2D(),
        keras.layers.Dropout(0.5),
        keras.layers.Dense(num_classes, activation="softmax"),
    ]
)
```

ë‹¤ìŒì€ ìš°ë¦¬ ëª¨ë¸ì˜ ìš”ì•½ì…ë‹ˆë‹¤:


```python
model.summary()
```

`compile()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜µí‹°ë§ˆì´ì €, ì†ì‹¤ í•¨ìˆ˜ ë° ëª¨ë‹ˆí„°ë§í•  í‰ê°€ì§€í‘œë“¤ì„ ì§€ì •í•©ë‹ˆë‹¤. JAX ë° TensorFlow ë°±ì—”ë“œì—ì„œ XLA ì»´íŒŒì¼ì´ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆìŒì„ ì£¼ì˜í•˜ì„¸ìš”.







```python
model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    metrics=[
        keras.metrics.SparseCategoricalAccuracy(name="acc"),
    ],
)
```

ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•´ ë´…ì‹œë‹¤.
í›ˆë ¨ ì¤‘ì— ë³´ì§€ ì•Šì€ ë°ì´í„°ì— ëŒ€í•œ ì¼ë°˜í™”ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ ë°ì´í„°ì˜ 15%ë¥¼ ê²€ì¦ ë¶„í• ë¡œ ë”°ë¡œ ë–¼ì–´ ë†“ê² ìŠµë‹ˆë‹¤.


```python
batch_size = 128
epochs = 20

callbacks = [
    keras.callbacks.ModelCheckpoint(filepath="model_at_epoch_{epoch}.keras"),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=2),
]

model.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=epochs,
    validation_split=0.15,
    callbacks=callbacks,
)
score = model.evaluate(x_test, y_test, verbose=0)
```

í›ˆë ¨ ì¤‘ì— ë§¤ ì—í­ì˜ ëì—ì„œ ëª¨ë¸ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ëª¨ë¸ì„ ê°€ì¥ ìµœê·¼ ìƒíƒœë¡œë„ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:


```python
model.save("final_model.keras")
```

ê·¸ë¦¬ê³  ë‹¤ìŒê³¼ ê°™ì´ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
model = keras.saving.load_model("final_model.keras")
```

ë‹¤ìŒìœ¼ë¡œ, `predict()`ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ í™•ë¥ ì˜ ì˜ˆì¸¡ì„ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:


```python
predictions = model.predict(x_test)
```

ê¸°ë³¸ ì‚¬í•­ì€ ì´ê²ƒìœ¼ë¡œ ëì…ë‹ˆë‹¤!

# í¬ë¡œìŠ¤-í”„ë ˆì„ì›Œí¬ ì»¤ìŠ¤í…€ ì»´í¬ë„ŒíŠ¸ ì‘ì„±(Writing cross-framework custom components)
ì¼€ë¼ìŠ¤ ì½”ì–´ëŠ” ë™ì¼í•œ ì½”ë“œë² ì´ìŠ¤ë¡œ TensorFlow, JAX, PyTorchì—ì„œ ì‘ë™í•˜ëŠ” ì»¤ìŠ¤í…€ ë ˆì´ì–´, ëª¨ë¸, í‰ê°€ì§€í‘œ, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ë¨¼ì € ì»¤ìŠ¤í…€ ë ˆì´ì–´ë¥¼ ì‚´í´ë´…ì‹œë‹¤.

`tf.keras`ì—ì„œ ì»¤ìŠ¤í…€ ë ˆì´ì–´ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì„ ì´ë¯¸ ì•Œê³  ìˆë‹¤ë©´ â€” ì¢‹ìŠµë‹ˆë‹¤, ì•„ë¬´ê²ƒë„
ìˆ˜ì •í•  í•„ìš” ì—†ìŠµë‹ˆë‹¤. í•˜ë‚˜ë§Œ ì œì™¸í•˜ê³ : `tf` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  `keras.ops.*`ì—ì„œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

`keras.ops` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤.:

- NumPy APIì˜ êµ¬í˜„, ì˜ˆë¥¼ ë“¤ì–´ `keras.ops.stack` ë˜ëŠ” `keras.ops.matmul.`
- NumPyì— ì—†ëŠ” ì‹ ê²½ë§ íŠ¹ì • ì‘ì—…ì˜ ì§‘í•©, ì˜ˆë¥¼ ë“¤ì–´ `keras.ops.conv` ë˜ëŠ” `keras.ops.binary_crossentropy.`

ëª¨ë“  ë°±ì—”ë“œì—ì„œ ì‘ë™í•˜ëŠ” ì»¤ìŠ¤í…€ `Dense` ë ˆì´ì–´ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤:







```python

class MyDense(keras.layers.Layer):
    def __init__(self, units, activation=None, name=None):
        super().__init__(name=name)
        self.units = units
        self.activation = keras.activations.get(activation)

    def build(self, input_shape):
        input_dim = input_shape[-1]
        self.w = self.add_weight(
            shape=(input_dim, self.units),
            initializer=keras.initializers.GlorotNormal(),
            name="kernel",
            trainable=True,
        )

        self.b = self.add_weight(
            shape=(self.units,),
            initializer=keras.initializers.Zeros(),
            name="bias",
            trainable=True,
        )

    def call(self, inputs):
        # ì¼€ë¼ìŠ¤ ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ ë°±ì—”ë“œì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ë ˆì´ì–´/í‰ê°€ì§€í‘œ/ë“±ì„ ìƒì„±í•©ë‹ˆë‹¤.
        x = keras.ops.matmul(inputs, self.w) + self.b
        return self.activation(x)

```


ë‹¤ìŒìœ¼ë¡œ, `keras.random` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ì˜ì¡´í•˜ëŠ” ì»¤ìŠ¤í…€ `Dropout` ë ˆì´ì–´ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤:


```python

class MyDropout(keras.layers.Layer):
    def __init__(self, rate, name=None):
        super().__init__(name=name)
        self.rate = rate
        # RNG ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•´ seed_generatorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # ì´ê²ƒì€ ìƒíƒœ ìš”ì†Œì´ë©° seed ë³€ìˆ˜ëŠ”
        # `layer.variables`ì˜ ì¼ë¶€ë¡œ ì¶”ì ë©ë‹ˆë‹¤.
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        # ëœë¤ ì—°ì‚°ì„ ìœ„í•´ keras_core.randomì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        return keras.random.dropout(inputs, self.rate, seed=self.seed_generator)

```

ë‹¤ìŒìœ¼ë¡œ, ë‘ ì»¤ìŠ¤í…€ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ì„œë¸Œí´ë˜ìŠ¤ ëª¨ë¸ì„ ì‘ì„±í•´ë´…ì‹œë‹¤:


```python

class MyModel(keras.Model):
    def __init__(self, num_classes):
        super().__init__()
        self.conv_base = keras.Sequential(
            [
                keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
                keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
                keras.layers.MaxPooling2D(pool_size=(2, 2)),
                keras.layers.Conv2D(128, kernel_size=(3, 3), activation="relu"),
                keras.layers.Conv2D(128, kernel_size=(3, 3), activation="relu"),
                keras.layers.GlobalAveragePooling2D(),
            ]
        )
        self.dp = MyDropout(0.5)
        self.dense = MyDense(num_classes, activation="softmax")

    def call(self, x):
        x = self.conv_base(x)
        x = self.dp(x)
        return self.dense(x)

```


ì´ë¥¼ ì»´íŒŒì¼í•˜ê³  í•™ìŠµì‹œì¼œë´…ì‹œë‹¤:


```python
model = MyModel(num_classes=10)
model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    metrics=[
        keras.metrics.SparseCategoricalAccuracy(name="acc"),
    ],
)

model.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=1,  # ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´
    validation_split=0.15,
)
```

# ì„ì˜ì˜ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ëª¨ë¸ í•™ìŠµí•˜ê¸° (Training models on arbitrary data sources)
ëª¨ë“  ì¼€ë¼ìŠ¤ ëª¨ë¸ì€ ì‚¬ìš©í•˜ëŠ” ë°±ì—”ë“œì— ìƒê´€ì—†ì´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ í›ˆë ¨ ë° í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:

- NumPy ë°°ì—´
- Pandas ë°ì´í„°í”„ë ˆì„
- TensorFlow `tf.data.Dataset` ê°ì²´
- PyTorch `DataLoader` ê°ì²´
- Keras `PyDataset` ê°ì²´

ì´ë“¤ì€ TensorFlow, JAX, ë˜ëŠ” PyTorchë¥¼ ì¼€ë¼ìŠ¤ ë°±ì—”ë“œë¡œ ì‚¬ìš©í•˜ë“  ìƒê´€ì—†ì´ ëª¨ë‘ ì‘ë™í•©ë‹ˆë‹¤.

PyTorch `DataLoaders`ë¡œ ì‹œë„í•´ë´…ì‹œë‹¤:


```python
import torch

# TensorDataset ìƒì„±
train_torch_dataset = torch.utils.data.TensorDataset(
    torch.from_numpy(x_train), torch.from_numpy(y_train)
)
val_torch_dataset = torch.utils.data.TensorDataset(
    torch.from_numpy(x_test), torch.from_numpy(y_test)
)

# DataLoader ìƒì„±
train_dataloader = torch.utils.data.DataLoader(
    train_torch_dataset, batch_size=batch_size, shuffle=True
)
val_dataloader = torch.utils.data.DataLoader(
    val_torch_dataset, batch_size=batch_size, shuffle=False
)

model = MyModel(num_classes=10)
model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    metrics=[
        keras.metrics.SparseCategoricalAccuracy(name="acc"),
    ],
)
model.fit(train_dataloader, epochs=1, validation_data=val_dataloader)

```

ì´ì œ `tf.data`ë¡œë„ ì‹œë„í•´ ë´…ì‹œë‹¤:


```python
import tensorflow as tf

train_dataset = (
    tf.data.Dataset.from_tensor_slices((x_train, y_train))
    .batch(batch_size)
    .prefetch(tf.data.AUTOTUNE)
)
test_dataset = (
    tf.data.Dataset.from_tensor_slices((x_test, y_test))
    .batch(batch_size)
    .prefetch(tf.data.AUTOTUNE)
)

model = MyModel(num_classes=10)
model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    metrics=[
        keras.metrics.SparseCategoricalAccuracy(name="acc"),
    ],
)
model.fit(train_dataset, epochs=1, validation_data=test_dataset)
```

## ì¶”ê°€ í•™ìŠµ ìë£Œ (Further reading)
ì´ê²ƒìœ¼ë¡œ ì¼€ë¼ìŠ¤ ì½”ì–´ì˜ ìƒˆë¡œìš´ ë©€í‹° ë°±ì—”ë“œ ê¸°ëŠ¥ì— ëŒ€í•œ ì§§ì€ ê°œìš”ë¥¼ ë§ˆì¹©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì´ê²ƒë“¤ì„ ë°°ìš¸ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤ :

### `fit()`ì—ì„œ ì¼ì–´ë‚˜ëŠ” ê²ƒì„ ì–´ë–»ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í• ê¹Œìš”?
ë¹„í‘œì¤€ í›ˆë ¨ ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ êµ¬í˜„í•˜ë ¤ê³  í•˜ì§€ë§Œ (ì˜ˆ: GAN í›ˆë ¨ ë£¨í‹´) ì—¬ì „íˆ `fit()`ì˜ í˜ê³¼ ì‚¬ìš©ì„±ì„ ëˆ„ë¦¬ê³  ì‹¶ë‹¤ë©´, `fit()`ì„ ì„ì˜ì˜ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì§€ì›í•˜ë„ë¡ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ê²ƒì´ ì •ë§ ì‰½ìŠµë‹ˆë‹¤.

- [TensorFlowì—ì„œ `fit()`ì—ì„œ ì¼ì–´ë‚˜ëŠ” ê²ƒì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ë°©ë²•](http://keras.io/keras_core/guides/custom_train_step_in_tensorflow/)
-[JAXì—ì„œ `fit()`ì—ì„œ ì¼ì–´ë‚˜ëŠ” ê²ƒì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ë°©ë²•](http://keras.io/keras_core/guides/custom_train_step_in_jax/)
-[PyTorchì—ì„œ `fit()`ì—ì„œ ì¼ì–´ë‚˜ëŠ” ê²ƒì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ë°©ë²•](http://keras.io/keras_core/guides/custom_train_step_in_pytorch/)

## ì»¤ìŠ¤í…€ í›ˆë ¨ ë£¨í”„ ì‘ì„± ë°©ë²• (How to write custom training loops)
- [TensorFlowì—ì„œ ì²˜ìŒë¶€í„° í›ˆë ¨ ë£¨í”„ ì‘ì„±í•˜ëŠ” ë°©ë²•](http://keras.io/keras_core/guides/writing_a_custom_training_loop_in_tensorflow/)
-[JAXì—ì„œ ì²˜ìŒë¶€í„° í›ˆë ¨ ë£¨í”„ ì‘ì„±í•˜ëŠ” ë°©ë²•](http://keras.io/keras_core/guides/writing_a_custom_training_loop_in_jax/)
-[PyTorchì—ì„œ ì²˜ìŒë¶€í„° í›ˆë ¨ ë£¨í”„ ì‘ì„±í•˜ëŠ” ë°©ë²•](http://keras.io/keras_core/guides/writing_a_custom_training_loop_in_torch/)

## í›ˆë ¨ ë¶„ë°° ë°©ë²• (How to distribute training)
- [TensorFlowì™€ í•¨ê»˜ ë¶„ì‚° í›ˆë ¨ ê°€ì´ë“œ](http://keras.io/keras_core/guides/distributed_training_with_tensorflow/)
- [JAX ë¶„ì‚° í›ˆë ¨ ì˜ˆì œ](https://github.com/keras-team/keras-core/blob/main/examples/demo_jax_distributed.py)
- [PyTorch ë¶„ì‚° í›ˆë ¨ ì˜ˆì œ](https://github.com/keras-team/keras-core/blob/main/examples/demo_torch_multi_gpu.py)

ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¦ê¸°ì„¸ìš”! ğŸš€
